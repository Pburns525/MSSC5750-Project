---
title: "Final Project"
author: "David, Michael, Patrick"
format: html
---


```{r echo = FALSE, message=FALSE}
library(MASS)
library(ggplot2)
library(dplyr)
library(scales)
library(glmnet)
library(fastDummies)
library(caret)

# Importing data set from github repository
data <- read.csv("https://raw.githubusercontent.com/Pburns525/MSSC5750-Project/refs/heads/main/loan_data.csv")

```


High-Level Data Exploration
```{r}

nrow(data)
colnames(data)

# There is no missing data, already a cleaned data set
colSums(is.na(data))

table(data$person_gender)

# Education is not currently ordered, change to a factor and set levels
data$person_education<- factor(data$person_education, levels=c('High School','Associate','Bachelor','Master','Doctorate'), ordered=TRUE)
table(data$person_education)

# Looks like we have somebody who is 144 yrs old, 7 who are over age 100. PRobably want to remove them, its doubtful anybody very old would be applying anyways, and these ages are not really possible
summary(data$person_age)
sum(data$person_age>100)

summary(data$person_income)

summary(data$loan_amnt)

table(data$loan_intent)

summary(data$cb_person_cred_hist_length)

summary(data$loan_percent_income)

summary(data$credit_score)

table(data$person_home_ownership)

# This is years of employment experience. Again we see some super high values, longer than human lifespan, so should clean those up
summary(data$person_emp_exp)
sum(data$person_emp_exp>70)

table(data$previous_loan_defaults_on_file)

# 22% of our data receives a loan, so our dataset is imbalanced, but not too extreme
percent(table(data$loan_status)[2]/nrow(data),accuracy=1)

```  

Creating some basic visualizations
```{R}

# Removing outliers (Somebody was earning like 7M, we have almost 25 who are over 1M still)
ggplot(data=data %>% filter(person_income<500000), aes(x=person_income)) +geom_histogram(bins=30)

#Actually might be better to just add a catch bucket at the end. IF over 250k, just set to 250k
ggplot(data=data %>% mutate(person_income2 = if_else(person_income<250000,person_income,250000)), aes(x=person_income2)) +geom_histogram(bins=40, fill='steelblue',color='black') + xlab("Income") + ggtitle("Histogram of Income")+
  scale_x_continuous(breaks=seq(0,250000,50000), labels=c("$0","$50,000","$100,000","$150,000","$200,000","$250,000+") )


```


 Outline for LASSO regression to help with variable selection
```{R}

# One-hot-encoding our categorical variables. Should happen automatically for factors
data$person_gender <- as.factor(data$person_gender)
data$person_home_ownership<-as.factor(data$person_home_ownership)
data$loan_intent<-as.factor(data$loan_intent)
data$previous_loan_defaults_on_file<-as.factor(data$previous_loan_defaults_on_file)

# Extracting outcome variable
class <- data$loan_status

# Converting to a matrix
matrixData <- model.matrix(class ~ ., data = data %>% select(-loan_status))

# First column is all intercepts
matrixData<- matrixData[,-1]

# Uses cross validation, no need to train/test split. Alpha selects lasso (rather than ridge regression), but I think thats the default anyways
lasso <- cv.glmnet(matrixData, class, alpha = 1, family = "binomial")

# See coefficients, which variables we might drop
coef(lasso)

# Make predictions
data$lassoPred <- as.vector(predict(lasso, newx = matrixData, type = "class"))

# Evaluate accuracy measures
confusionMatrix(factor(data$lassoPred), factor(data$loan_status), positive = '1')

```



